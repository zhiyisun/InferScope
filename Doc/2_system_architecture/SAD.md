<!-- AUTO-GENERATED from architecture.yaml -->
<!-- Do not edit this file directly. Edit architecture.yaml and run: python scripts/generate_sad.py -->

# System Architecture Document (SAD)

## High-Level Architecture

```
+-------------------+
|   User Workload   |
|  (PyTorch App)    |
+-------------------+
        |
        | (NVTX markers, Python hooks)
        v
+-------------------+
| Trace Collectors  |
+-------------------+
        |
        +---> CPU Collector (Python profiler + sys.settrace)
        |
        +---> GPU Collector (CUPTI)
        |
        +---> Memory Collector (procfs, NUMA APIs)
        |
        v
+-------------------+
| Trace Buffer      |
| (Ring Buffer)     |
+-------------------+
        |
        v
+-------------------+
| Timeline Merger   |
| (Clock sync +     |
|  Event ordering)  |
+-------------------+
        |
        v
+-------------------+
| Analyzer Engine   |
| (Bottleneck rules)|
+-------------------+
        |
        v
+-------------------+
| Report Generator  |
| (Markdown/HTML)   |
+-------------------+
        |
        v
+-------------------+
|   Output Report   |
+-------------------+
```

## Component Responsibilities

### 1. Analyzer Engine
- **Responsibility**: Detect and classify bottlenecks
- **Interfaces**: Unified timeline (read), Report generator (write analysis)
- **Rules**:
  - GPU idle detection (>10% idle → CPU-bound)
  - PCIe saturation (H2D+D2H throughput)
  - CPU threading contention
  - Memory pressure

### 2. Cpu Collector
- **Responsibility**: Capture Python function calls and CPU time
- **Technology**: sys.settrace(), perf, /proc/self/stat
- **Interfaces**: Trace buffer (write-only)
- **Concurrency**: Per-thread TLS buffer, lock-free

### 3. Gpu Collector
- **Responsibility**: Capture CUDA kernels, memory transfers, GPU execution
- **Technology**: NVIDIA CUPTI (Callback & Activity API)
- **Interfaces**: Trace buffer (write-only)
- **Concurrency**: Main thread only; async collection via callbacks

### 4. Memory Collector
- **Responsibility**: Track memory pressure, NUMA overhead
- **Technology**: Linux perf, /proc/self/numa_stat
- **Interfaces**: Trace buffer (write-only)
- **Concurrency**: Periodic sampling, lock-free

### 5. Report Generator
- **Responsibility**: Create human-readable reports
- **Interfaces**: Analysis results (read), File output (write)
- **Output Formats**: Markdown (default), HTML (optional), JSON (machine-readable)

### 6. Timeline Merger
- **Responsibility**: Synchronize CPU/GPU clocks, order events globally
- **Technology**: CUDA event-based clock calibration + rdtsc
- **Interfaces**: Trace buffer (read), Analyzer engine (write unified timeline)
- **Concurrency**: Single-threaded, post-collection
- **Accuracy**: <1% clock error

### 7. Trace Buffer
- **Responsibility**: Store events without blocking collectors
- **Technology**: In-memory ring buffer (circular queue)
- **Interfaces**: Collectors (write), Timeline merger (read)
- **Default Size**: 100 MB
- **Overflow Behavior**: Wrap oldest events

## Data Flow

1. **Collection Phase** (parallel):
   - CPU events → CPU Collector → Trace Buffer
   - GPU events → GPU Collector → Trace Buffer
   - Memory events → Memory Collector → Trace Buffer

2. **Merger Phase** (sequential):
   - Read all events from Trace Buffer
   - Synchronize clocks
   - Sort by global timestamp
   - Output unified timeline

3. **Analysis Phase** (sequential):
   - Apply bottleneck rules to timeline
   - Classify idle periods, transfers, compute
   - Generate root cause analysis

4. **Reporting Phase** (sequential):
   - Format timeline for report
   - Render statistics and suggestions
   - Output Markdown/HTML

## External Interfaces

### Python API
```python
from inferscope import scope

with scope("inference_step"):
    output = model.forward(inputs)
```

### CLI Interface
```bash
inferscope run <script> --report report.md
inferscope analyze <trace.json>
inferscope config show
```

### Configuration
- **Precedence**: CLI arguments (highest priority) > Environment variables > .inferscope.yaml (lowest priority)
- **Environment Variables**:
  - `INFERSCOPE_ENABLE=1`
  - `INFERSCOPE_LOG_LEVEL=debug`
  - `INFERSCOPE_TRACE_SIZE_MB=200`

## Threading & Concurrency Model

- **Cpu Collector**: Per-thread TLS buffer, lock-free
- **Gpu Collector**: Main thread only; async collection via callbacks
- **Memory Collector**: Periodic sampling, lock-free
- **Timeline Merger**: Single-threaded, post-collection

## Failure Modes & Mitigations

| Failure | Mitigation |
|---------|-----------|
| CUDA initialization fails | Fallback to CPU-only analysis |
| CUPTI unavailable | Graceful degradation: warn + CPU-only |
| Trace buffer overflow | Ring buffer wraps; oldest events discarded |
| Clock sync error | Use conservative sync margin; report uncertainty |
| Memory pressure | Emit warning; reduce buffer size |
