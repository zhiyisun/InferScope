<!-- AUTO-GENERATED from architecture.yaml -->
<!-- Do not edit this file directly. Edit architecture.yaml and run: python scripts/generate_docs.py -->

# System Architecture Document (SAD)

## High-Level Architecture

```
+-------------------+
|   User Workload   |
|  (PyTorch App)    |
+-------------------+
        |
        | (NVTX markers, Python hooks)
        v
+-------------------+
| Trace Collectors  |
+-------------------+
        |
        +---> CPU Collector (Python profiler + sys.settrace)
        |
        +---> GPU Collector (CUPTI)
        |
        +---> Memory Collector (procfs, NUMA APIs)
        |
        v
+-------------------+
| Timeline Merger   |
|  - clock sync     |
|  - event ordering |
+-------------------+
        |
        v
+-------------------+
| Analyzer Engine   |
|  - bottlenecks    |
|  - root causes    |
|  - suggestions    |
+-------------------+
        |
        v
+-------------------+
| Report Generator  |
|  - Markdown/HTML  |
+-------------------+
```

## Component Responsibilities

### analyzer_engine
- **Responsibility**: Detect and classify bottlenecks
- **Interfaces**:
  - Unified timeline (read)
  - Report generator (write analysis)

### cpu_collector
- **Responsibility**: Capture Python function calls and CPU time
- **Technology**: sys.settrace(), perf, /proc/self/stat
- **Concurrency**: Per-thread TLS buffer, lock-free
- **Interfaces**:
  - Trace buffer (write-only)

### gpu_collector
- **Responsibility**: Capture CUDA kernels, memory transfers, GPU execution
- **Technology**: NVIDIA CUPTI (Callback & Activity API)
- **Concurrency**: Main thread only; async collection via callbacks
- **Interfaces**:
  - Trace buffer (write-only)

### memory_collector
- **Responsibility**: Track memory pressure, NUMA overhead
- **Technology**: Linux perf, /proc/self/numa_stat
- **Concurrency**: Periodic sampling, lock-free
- **Interfaces**:
  - Trace buffer (write-only)

### report_generator
- **Responsibility**: Create human-readable reports
- **Interfaces**:
  - Analysis results (read)
  - File output (write)

### timeline_merger
- **Responsibility**: Synchronize CPU/GPU clocks, order events globally
- **Technology**: CUDA event-based clock calibration + rdtsc
- **Concurrency**: Single-threaded, post-collection
- **Interfaces**:
  - Trace buffer (read)
  - Analyzer engine (write unified timeline)

### trace_buffer
- **Responsibility**: Store events without blocking collectors
- **Technology**: In-memory ring buffer (circular queue)
- **Interfaces**:
  - Collectors (write)
  - Timeline merger (read)

## Design Principles
1. **Composability**: Each component is independent and testable
2. **Observability**: Every operation is logged and traceable
3. **Correctness**: All timings are verified and cross-checked
4. **Clarity**: Reports explain causes, not just statistics
